{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Some pactice for CNN and RNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tensorflow.contrib import rnn\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.reset_default_graph()\n",
    "from IPython.core.display import Image, display\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use CNN to train MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define estimators functions using `tf.estimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateEstimatorSpec(logits, labels, mode):\n",
    "    # Generate Predictions\n",
    "    predictions = {\n",
    "      \"classes\": tf.argmax(input = logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    print(tf.argmax(input = logits, axis=1))\n",
    "    # If during training mode, just return the predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, \n",
    "                                          predictions = predictions)\n",
    "    \n",
    "    # If during Train or Eval, calculate cross-entropy loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, \n",
    "                                                  logits = logits)\n",
    "\n",
    "    # If during Train, update gradients\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss = loss,\n",
    "            global_step = tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, \n",
    "                                          loss = loss, \n",
    "                                          train_op = train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels = labels, \n",
    "              predictions = predictions[\"classes\"])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode = mode, loss = loss, eval_metric_ops = eval_metric_ops) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN network using `layers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params = None): #params will be used for hyper params\n",
    "    \n",
    "    # features: This is the first item returned from the input_fn passed to train\n",
    "    # labels: This is the second item returned from the input_fn passed to train\n",
    "    \n",
    "    #input layer (reshape from 784 cells)\n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1]) \n",
    "    #[batch_size, image_width, image_height, channels], -1: dynamic compute\n",
    "    \n",
    "    # Convolutonal Layer 1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs = input_layer,\n",
    "        filters = 32, #number of filters\n",
    "        kernel_size = [5,5], #filter size, or kernel_size = 5\n",
    "        strides=(1, 1), #move along 2 dirs\n",
    "        padding = \"same\", # other options: \"valid\"\n",
    "        activation = tf.nn.relu,\n",
    "        name = \"CL_1\"\n",
    "        )\n",
    "    \n",
    "    # Note the output dimension: 28 * 28 * 32\n",
    "    \n",
    "    # Pooling Layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs = conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)\n",
    "    \n",
    "    # Note the output dimension: 14 * 14 * 32\n",
    "    \n",
    "    # Convolutonal Layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs = pool1,\n",
    "        filters = 64, #number of filters\n",
    "        kernel_size = [5,5], #filter size\n",
    "        padding = \"same\", # other options: \"valid\"\n",
    "        activation = tf.nn.relu,\n",
    "        name = \"CL_2\"\n",
    "    )\n",
    "    \n",
    "    # Note the output dimension: 14 * 14 * 64\n",
    "    \n",
    "    # Pooling Layer 2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs = conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)\n",
    "    \n",
    "    # Note the output dimension: 7 * 7 * 64\n",
    "    \n",
    "    # Flatten layer (same below??)\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64]) # 3136 weights\n",
    "    pool2_flat = tf.layers.flatten(pool2)\n",
    "    \n",
    "    # FC layer (dense layer)\n",
    "    dense = tf.layers.dense(inputs = pool2_flat, \n",
    "                            units=1024, # 3136 --> 1024\n",
    "                            activation = tf.nn.relu)\n",
    "    \n",
    "    # Drop-out layer\n",
    "    dropout = tf.layers.dropout(inputs=dense, \n",
    "                                rate=0.4, \n",
    "                    training = mode == tf.estimator.ModeKeys.TRAIN)# only activate during training\n",
    "    \n",
    "    # Final layer (10 logits)\n",
    "    logits = tf.layers.dense(inputs = dropout, units = 10)\n",
    "    \n",
    "\n",
    "\n",
    "    Final_EstimatorSpec = GenerateEstimatorSpec(logits, labels, mode)\n",
    "    return(Final_EstimatorSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns model input\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data}, # features \n",
    "    y=train_labels, # targets\n",
    "    batch_size = 100, \n",
    "    num_epochs = None, # forever, the model will train until the specified number of steps is reached\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model_files', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c1567eda0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function cnn_model_fn at 0x103076378>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn = cnn_model_fn, # model function type, \n",
    "    model_dir = \"./model_files\",\n",
    "    params = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_1:0\", shape=(100,), dtype=int64)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./model_files/model.ckpt-2\n",
      "INFO:tensorflow:Saving checkpoints for 3 into ./model_files/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.305, step = 3\n",
      "INFO:tensorflow:Saving checkpoints for 12 into ./model_files/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.30147.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c1567e320>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train(\n",
    "    input_fn = train_input_fn,\n",
    "    steps = 10) # for testing purpose\n",
    "    #hooks = [logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_1:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-30-00:22:46\n",
      "INFO:tensorflow:Restoring parameters from ./model_files/model.ckpt-12\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-30-00:22:52\n",
      "INFO:tensorflow:Saving dict for global step 12: accuracy = 0.1444, global_step = 12, loss = 2.30339\n",
      "{'accuracy': 0.1444, 'loss': 2.303391, 'global_step': 12}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data}, #features \n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RNN (`LSTM`) to train `sum` operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model_fn(features, labels, mode, params = None): #params will be used for hyper params\n",
    "    \n",
    "    num_time_steps = 12;\n",
    "    num_dims = 1;\n",
    "    num_hidden_units = 24;\n",
    "    num_outputs = 13;\n",
    "    \n",
    "    input_layer = tf.unstack(features['x'], num_time_steps, num_dims)# (data, time_steps, 1), cut into 10 pieces\n",
    "    \n",
    "    lstm_layer = rnn.BasicLSTMCell(num_hidden_units )\n",
    "    \n",
    "    outputs, _ = rnn.static_rnn(lstm_layer, input_layer ,dtype = \"float32\")\n",
    "    \n",
    "    logits = tf.layers.dense(inputs = outputs[-1], units = num_outputs)\n",
    "    \n",
    "    Final_EstimatorSpec = GenerateEstimatorSpec(logits, labels, mode)\n",
    "    return(Final_EstimatorSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = ['{0:012b}'.format(i) for i in range(2**12)] \n",
    "shuffle(train_input)\n",
    "ti  = []\n",
    "for i in train_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "        temp_list.append([j])\n",
    "    ti.append(temp_list)\n",
    "\n",
    "train_input = np.array(ti, dtype=np.float32)\n",
    "train_input[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = []\n",
    "for i in train_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    train_output.append(count)\n",
    "\n",
    "train_output = np.array(train_output, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 4000\n",
    "train_data = train_input[:NUM_EXAMPLES]\n",
    "train_labels = train_output[:NUM_EXAMPLES]\n",
    "eval_data = train_input[NUM_EXAMPLES:]\n",
    "eval_labels = train_output[NUM_EXAMPLES:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns model input\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data}, # features \n",
    "    y=train_labels, # targets\n",
    "    batch_size = 5, \n",
    "    num_epochs = None, # forever, the model will train until the specified number of steps is reached\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model_files_2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c1602d2b0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function rnn_model_fn at 0x1c1629ef28>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "sum_classifier = tf.estimator.Estimator(\n",
    "    model_fn = rnn_model_fn, # model function type, \n",
    "    model_dir = \"./model_files_2\",\n",
    "    params = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_1:0\", shape=(5,), dtype=int64)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./model_files_2/model.ckpt-60002\n",
      "INFO:tensorflow:Saving checkpoints for 60003 into ./model_files_2/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.799017, step = 60003\n",
      "INFO:tensorflow:Saving checkpoints for 60012 into ./model_files_2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.878255.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1c1602deb8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_classifier.train(\n",
    "    input_fn = train_input_fn,\n",
    "    steps = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_1:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-30-00:25:22\n",
      "INFO:tensorflow:Restoring parameters from ./model_files_2/model.ckpt-60012\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-30-00:25:22\n",
      "INFO:tensorflow:Saving dict for global step 60012: accuracy = 0.864583, global_step = 60012, loss = 0.611921\n",
      "{'accuracy': 0.86458331, 'loss': 0.61192131, 'global_step': 60012}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": eval_data}, #features \n",
    "    y = eval_labels,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "eval_results = sum_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the model and print results\n",
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data}, #features \n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_results = sum_classifier.predict(input_fn=pred_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_1:0\", shape=(?,), dtype=int64)\n",
      "INFO:tensorflow:Restoring parameters from ./model_files_2/model.ckpt-60012\n",
      "[5, 7, 6, 7, 4, 8, 6, 7, 6, 5]\n"
     ]
    }
   ],
   "source": [
    "pred_classes = []\n",
    "for i in pred_results:\n",
    "    pred_classes.append(i['classes'])\n",
    "print(pred_classes[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RNN(LSTM) to train `sum` Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Straight forward example to predict many-to-one problem\n",
    "\n",
    "how to predict '[0,1,1,0]' to 2 (SUM)\n",
    "\n",
    "http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "from tensorflow.contrib import rnn\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = ['{0:010b}'.format(i) for i in range(2**10)]\n",
    "shuffle(train_input)\n",
    "train_input = [map(int,i) for i in train_input]\n",
    "ti  = []\n",
    "for i in train_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "            temp_list.append([j])\n",
    "    ti.append(np.array(temp_list))\n",
    "train_input = ti\n",
    "\n",
    "train_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output = []\n",
    "for i in train_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    temp_list = ([0]*11)\n",
    "    temp_list[count]=1\n",
    "    train_output.append(temp_list)\n",
    "\n",
    "train_output[0] # one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 900\n",
    "test_input = train_input[NUM_EXAMPLES:]\n",
    "test_output = train_output[NUM_EXAMPLES:]\n",
    "train_input = train_input[:NUM_EXAMPLES]\n",
    "train_output = train_output[:NUM_EXAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10), Dimension(1)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.placeholder(tf.float32, [None, 10, 1]) # Batch_size, Timestep, dimension of each input\n",
    "input = tf.unstack(data, 10, 1)# (data, time_steps, 1), cut into 10 pieces\n",
    "y = tf.placeholder(tf.float32, [None, 11])\n",
    "\n",
    "num_hidden = 24\n",
    "lstm_layer = rnn.BasicLSTMCell(num_hidden)\n",
    "outputs, _ = rnn.static_rnn(lstm_layer, input,dtype = \"float32\")\n",
    "\n",
    "out_weights = tf.Variable(tf.random_normal([num_hidden, 11]))\n",
    "out_bias = tf.Variable(tf.random_normal([11]))\n",
    "prediction = tf.matmul(outputs[-1], out_weights)+ out_bias\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = prediction, labels = y))\n",
    "opt = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)\n",
    "\n",
    "batch_size = 10\n",
    "no_of_batches = int(len(train_input) / batch_size)\n",
    "epoch = 100\n",
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_size]\n",
    "        ptr+=batch_size\n",
    "        acc, _ = sess.run([loss, opt],feed_dict={data: inp, y: out})\n",
    "        print(acc)\n",
    "\n",
    "acc = sess.run(accuracy,{data: test_input, y: test_output})\n",
    "print(sess.run(prediction,{data: [[[1],[0],[0],[1],[1],[0],[1],[1],[1],[0]]]}))\n",
    "print('Epoch {:2d} acc {:3.1f}%'.format(i + 1, 100 * acc))\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "398px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
