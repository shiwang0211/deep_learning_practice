{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Shilad_Sen/publication/221607721/figure/fig1/AS:305580804722702@1449867549680/Intermediary-entities-center-relate-user-to-recommended-item.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Workflow**\n",
    "- Generate features from user behavior (indirect) / user attributes (direct) for pairs of $(u,i)$\n",
    "    - Behavior weighing (view, click, purchase)\n",
    "    - Behavior time (recent or past)\n",
    "    - Behavior frequency\n",
    "    - Item popularity (more popular, less important)\n",
    "    \n",
    "    \n",
    "- Apply algorithms (as in following sections), and get candidate list of items\n",
    "    - For a give user feature vector, retrieve $(item, weight)$\n",
    "    - There can be multiple tables (e,g., one table for CF, one-table for content-based) or (e.g., one table for browse, one table for click)\n",
    "\n",
    "\n",
    "- Filtering based on business rules\n",
    "    - For example, only recommend new products\n",
    "    \n",
    "    \n",
    "- Ranking by some criterias\n",
    "    - For example, variety\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data also includes:\n",
    "- User Info (sex, income)\n",
    "- Item Info (BOW, TF-IDF)\n",
    "- User-Item Interaction\n",
    "    - active/explicit: rating\n",
    "    - passive/implicit: clickstream analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-based CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy import sparse\n",
    "from script import cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Example Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('./data/ml-100k/u.data', sep='\\t', names=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 943 | Number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print ('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrix = np.zeros((n_users, n_items))\n",
    "for line in df.itertuples():\n",
    "    df_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "df_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cosine Similarity\n",
    "$Similarity = cos(\\theta) = \\frac{\\mathbf A \\cdot \\mathbf B }{||\\mathbf A|| \\ ||\\mathbf B|| }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_similarity = np.zeros((n_users, n_users))\n",
    "for i in range(n_users):\n",
    "    u= df_matrix[i,]\n",
    "    for j in range(n_users):\n",
    "        v= df_matrix[j,]\n",
    "        user_similarity[i,j] = np.dot(u,v) / (np.linalg.norm(u,ord=2) * np.linalg.norm(v,ord=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 943)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(df_matrix, metric='cosine')\n",
    "user_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 1682)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity = pairwise_distances(df_matrix.T, metric='cosine')\n",
    "item_similarity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rating prediction: RMSE, MAE\n",
    "- Top-k rating precision: Precision, Recall, AUC\n",
    "    - % of the top-k recommendations that were actually used by user\n",
    "- Possible benchmark model: global top-k recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Item Filtering\n",
    "- Users who are similar to you also liked ...\n",
    "- Prediction for user __k__ for movie **m**:\n",
    "\n",
    "- Prediction = User **k** bias + adjustmemnt from similar user\n",
    "    - $ \\hat{x}_{k,m} = \\bar x_k + \\frac{\\Delta}{Norm}  $\n",
    "\n",
    "\n",
    "- Adjustment = (similarity with another user) * (rating of another user - bias of another user)\n",
    "    - $ \\Delta = \\sum_{k_0}UserSim(k, k_0) \\cdot (x_{k_0, m} - \\bar x_{k0})$\n",
    "\n",
    "    - $ Norm = \\sum_{k_0}|UserSim(k, k_0)|$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/cf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./script/cf.py\n",
    "import numpy as np\n",
    "\n",
    "def ui_predict(ratings, similarity):\n",
    "    all_user_mean = ratings.mean(axis = 1)\n",
    "    ratings_diff = (ratings - all_user_mean[:, np.newaxis]) # (943, 1682)\n",
    "    \n",
    "    adjust = similarity.dot(ratings_diff)\n",
    "    norm = np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "\n",
    "    pred = all_user_mean[:, np.newaxis] + adjust / norm\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from script.cf import *\n",
    "cf.ui_predict(df_matrix, user_similarity).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Item-Item Filtering\n",
    "Users who liked this item also liked ...\n",
    "- $ \\hat{x}_{k,m} = \\frac{\\sum_{m_0}ItemSim(m, m_0)}{Norm}  \\cdot x_{k, m_0}$\n",
    "   \n",
    "How to understand $ItemSim(m, m_0)$:\n",
    "- Dot product: number of users who like both item $m$ and item $m_0$ (If input matrix is not rating)\n",
    "- $ItemSim(m, m_0)$: added normalization to [0,1]\n",
    "\n",
    "Result:\n",
    "- Each item $m_0$ is contributing to rating of the target item $m$\n",
    "<img src=\"http://n.sinaimg.cn/sinacn23/279/w640h439/20180715/cbd7-hfkffak1630519.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to ./script/cf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a ./script/cf.py\n",
    "\n",
    "def ii_predict(ratings, similarity):\n",
    "    norm = np.array([np.abs(similarity).sum(axis=1)])\n",
    "    pred = ratings.dot(similarity)  / norm\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.ii_predict(df_matrix, item_similarity).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between user-based and item-based\n",
    "|User-based       | Item-based           | \n",
    "| ------------- |:-------------:| \n",
    "| more socialized      | more personalized | \n",
    "| fro example: news | for example: books|\n",
    "| update user-similarity matrix| update item-similarity matrix|\n",
    "| number of user << number of items | number of user >> number of items|\n",
    "| Not interpretable | Interpretable|\n",
    "| Cold starting: No problem for new items (after 1 action) | Cold starting: no problem for new users (after one action)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Based CF - Matrix Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization or Latent Factor Model\n",
    "Singular-Value-Decomposition\n",
    "\n",
    "- see SVD notebook for math behind SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sigopt.com/wp-content/uploads/2018/10/collaborative_filtering.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $M = U \\times \\Sigma \\times V^T  $ Note: $\\Sigma$ can be multipled to U or V\n",
    "- Con: need default value for missing value in rating matrix\n",
    "    - For like (0/1) or implicit feedback: \n",
    "    - 1) balanaced negative samples + postive samples\n",
    "    - 2) draw negative samples from popular items \n",
    "    \n",
    "    \n",
    "- U and V are low-dimention latent vectors (Embeddings) for users and movies. \n",
    "    - How to interpret this dimensions? Genres (i.e., users' preference for Genre $k$ and a given book's weight on genre $k$)\n",
    "    \n",
    "    \n",
    "- Alternative approach: $Min(L) = \\sum_{i,j}{(u_i v_j - x_{ij})^2} + Regularization (u,v)$\n",
    "    - Solved by SGD\n",
    "   \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u, s, vt = svds(df_matrix, k = 20)\n",
    "s_diag_matrix = np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1760/1*2i-GJO7JX0Yz6498jUvhEg.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other methods: \n",
    "- Probabilistic factorization (PMF)\n",
    "    * P = dot_product(i,j) + User_i_bias + movie_j_bias + intercept\n",
    "- Non-negative factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weighted rankings from two models\n",
    "- Cascade: 1) Accurate model -> rough rank; 2) 2nd one to refine\n",
    "- Treat collaborative factors as extra feature for content-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with memory-based CF\n",
    "- No need to store user-user ($ U \\times U $) or Item-Item ($ I \\times I$) similarity matrix in memory. The memory requirement is $F \\times (U + I)$\n",
    "- Matrix calculation on real-time is hard for large number of items, so mainly for off-line. Time complexity can be $F \\times U \\times I$. While memory-based method just needs a look-up table.\n",
    "- Hard to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Based CF - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Main difference with SVD\n",
    "    - Don't require orthogonal vectors as in SVD\n",
    "    - Learn the embedding by itself\n",
    "    - Allows non-linearity instead of just dot product\n",
    "    \n",
    "    \n",
    "- Extra benefits\n",
    "    - Can incoporate additional features like user profile\n",
    "    \n",
    "\n",
    "## Model Types\n",
    "\n",
    "### Idea 1\n",
    "- One-hot encoding for user i\n",
    "- Hiddern layer: Embedding layer for users\n",
    "    - Weights: latent vector for users\n",
    "    \n",
    "    \n",
    "- Output layer: output ratings for each item j\n",
    "    - Weights: latent vector for movies\n",
    "    \n",
    "    \n",
    "###  Idea 2\n",
    "- One-hot encoding for user i\n",
    "- Hiddern layer: Embedding layer for users\n",
    "    - Weights: latent vector for users\n",
    "    \n",
    "    \n",
    "- One-hot encoding for item j\n",
    "- Hidden layer: output ratings for each movie j\n",
    "    - Weights: latent vector for movies\n",
    "\n",
    "\n",
    "- More hidden layers\n",
    "    - Compared with matrix factorization, more representation power\n",
    "\n",
    "\n",
    "### Neural CF \n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/neuralcollaborativefiltering-170528094418/95/neural-collaborative-filtering-9-638.jpg?cb=1496201763\" width=\"600\">\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Neural CF in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Concatenate, Dense, Dropout\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_input = Input(shape = [1], name = 'Item-input')\n",
    "item_embedding = Embedding(n_items, n_latent_factors, name = 'Item-embedding')(item_input)\n",
    "item_flat = Flatten(name = 'Item-flatten')(item_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape = [1], name = 'User-input')\n",
    "user_embedding = Embedding(n_users, n_latent_factors, name = 'User-embedding')(user_input)\n",
    "user_flat = Flatten(name = 'User-flatten')(user_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "dotprod = Dot(axes=1, name='DotProduct')([item_flat, user_flat])\n",
    "model = Model([item_input, user_input ], dotprod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='./figure/model_ncf.png')\n",
    "#SVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/model_ncf.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate = Concatenate(name='Concatenate')([item_flat, user_flat])\n",
    "dropout = Dropout(0.2,name='Dropout')(concatenate)\n",
    "dense_1 = Dense(20,activation='relu', name='FC-1')(dropout)\n",
    "activation = Dense(1, activation='relu', name='Activation')(dense_1)\n",
    "model = Model([item_input, user_input ], activation)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='./figure/model_ncf2.png')\n",
    "#SVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/model_ncf2.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/15\n",
      " - 4s - loss: 1.5278 - val_loss: 0.9136\n",
      "Epoch 2/15\n",
      " - 3s - loss: 0.9126 - val_loss: 0.8956\n",
      "Epoch 3/15\n",
      " - 3s - loss: 0.8964 - val_loss: 0.8882\n",
      "Epoch 4/15\n",
      " - 3s - loss: 0.8809 - val_loss: 0.8799\n",
      "Epoch 5/15\n",
      " - 3s - loss: 0.8614 - val_loss: 0.8652\n",
      "Epoch 6/15\n",
      " - 3s - loss: 0.8486 - val_loss: 0.8639\n",
      "Epoch 7/15\n",
      " - 3s - loss: 0.8381 - val_loss: 0.8644\n",
      "Epoch 8/15\n",
      " - 3s - loss: 0.8255 - val_loss: 0.8608\n",
      "Epoch 9/15\n",
      " - 3s - loss: 0.8156 - val_loss: 0.8549\n",
      "Epoch 10/15\n",
      " - 3s - loss: 0.8033 - val_loss: 0.8568\n",
      "Epoch 11/15\n",
      " - 3s - loss: 0.7958 - val_loss: 0.8511\n",
      "Epoch 12/15\n",
      " - 3s - loss: 0.7857 - val_loss: 0.8489\n",
      "Epoch 13/15\n",
      " - 3s - loss: 0.7771 - val_loss: 0.8513\n",
      "Epoch 14/15\n",
      " - 3s - loss: 0.7703 - val_loss: 0.8451\n",
      "Epoch 15/15\n",
      " - 3s - loss: 0.7656 - val_loss: 0.8548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18198a7898>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://keras.io/models/model/\n",
    "model.fit(x = [df.item_id - 1, df.user_id - 1], \n",
    "          y = df.rating, \n",
    "          epochs = 15, \n",
    "          verbose = 2, \n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 20)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(name='User-embedding').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 20)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(name='Item-embedding').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Embedding / Content-basd Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different from item-based CF, where similarity is calculated based on user-item-interactions\n",
    "- Similarity is calculated based on item attribute (for example, location, price, cuisine, etc.)\n",
    "    - Output: An item space with defined distance\n",
    "- One model for one user; No interaction between users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item2Vec\n",
    "- Similar with Word2Vec, where each item is converted to a embedding vector\n",
    "\n",
    "$$E = -\\sum_i \\sum_j logP(j|i)$$\n",
    "- y=1 if item j and i appears in the same user's selection (i.e., in the same sentence)\n",
    "- Difference from word2vec: no time window restriction\n",
    "- Also applies negative sampling \n",
    "- Output: embedding of each item\n",
    "- (-) how to address items as a network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepWalk\n",
    "\n",
    "- Original user behaviors  (note: three different users in this example).\n",
    "- Construct item graph\n",
    "- Random walk sequences (**DFS** - Deep First Search)\n",
    "- Apply word2vec skipgram model\n",
    "<img src=\"./figure/deepwalk.png\" width=\"700\">\n",
    "\n",
    "### LINE（Large-scale Information Network Embedding）\n",
    "\n",
    "<img src=\"./figure/line.png\" width=\"500\">\n",
    "\n",
    "- Main Difference: Definition of higher order node similarity (e.g., node 5 and node 6)\n",
    "    - 1st order: \n",
    "    $$MinO_1 = d(p_1, w_1)$$\n",
    "    $$p_1(i,j)  = sigmoid(\\mathbf u_i^T \\cdot \\mathbf u_j)$$\n",
    "    \n",
    "    - 2nd order: \n",
    "    $$MinO_2 = d(p_2, w_2)$$\n",
    "    $$p_2(j|i)= softmax(\\mathbf u_i^T \\cdot \\mathbf u'_j)$$\n",
    "    \n",
    "    \n",
    "### node2vec\n",
    "\n",
    "<img src=\"./figure/node2vec.png\" width=\"500\">\n",
    "\n",
    "- Main Difference: Definition of node homophily (u, s1, s2, s3, s4) and structural equivalence (u, s6).\n",
    "\n",
    "- Homophily - DFS - red arrow\n",
    "- In RecoSys: same genre, attribute or purchased together.\n",
    "<img src=\"./figure/dfs.png\" width=\"500\">\n",
    "\n",
    "- Structural Equivalence - BFS - blue arrow\n",
    "- Best / Worst item of each genre, or other structural similarity.\n",
    "<img src=\"./figure/bfs.png\" width=\"500\">\n",
    "\n",
    "- Two parameters $p$ and $q$ jointly determines the balance between DFS and BFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alibaba: Enhanced Graph Embedding with Side Information\n",
    "ref: \n",
    "- https://arxiv.org/pdf/1803.02349.pdf\n",
    "- https://mp.weixin.qq.com/s/LrdmMi5ulmNZZpRN3HtHMQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Focus: Matching phase instead of ranking phase. The main goal is the item embedding, and item similarity.\n",
    "\n",
    "\n",
    "- Why not CF: CF depends on historial co-occurence of items under same user. It cannot capture higher-order\n",
    "similarities in users’ behavior sequence.\n",
    "\n",
    "\n",
    "- Problem with traditional graph embedding: some items with few interaction. How to do cold-starting.\n",
    "\n",
    "\n",
    "- Motivation: use **side information** to enhance the embeddings (e.g., category, brand, price) with different weights\n",
    "\n",
    "\n",
    "<img src=\"./figure/eges.png\" width=\"500\">\n",
    "\n",
    "- Solve for $W$ and $\\alpha$. \n",
    "    - j = 0 represents weights for item embedding\n",
    "    - j > 0 represents weights for side-info embedding\n",
    "$$H_v = \\frac{\\sum_j e^{\\alpha_j} \\cdot w_j}{\\sum e^{\\alpha}} $$\n",
    "\n",
    "- For cold start items without any interactions\n",
    "    - CF doesn't work\n",
    "    - Item graph cannot be constructed\n",
    "    - Represent it with **the average embeddings of its side information**, and calculate dot product with embeddings of other items.\n",
    "    \n",
    "<img src=\"./figure/cold_start.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airbnb:\n",
    "ref:\n",
    "- https://mp.weixin.qq.com/s/vZN5Jr8DWsDQvOToOCxSOg\n",
    "- https://dl.acm.org/doi/pdf/10.1145/3219819.3219885\n",
    "- https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/airbnb.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of loss function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The combined negative sampling loss function: \n",
    "    $$Loss = -[\\sum_{(l, c) \\in pos} log\\ \\sigma(u_c v_l^T) + \\sum_{(l, c) \\in neg_1} log\\ \\sigma(-u_c v_l^T) + log\\ \\sigma(u_{l_b} v_l^T) +  \\sum_{(l, c) \\in neg_2} log\\ \\sigma(-u_c v_l^T)]$$\n",
    "    - $l$: center listing, $c$: context listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Center listing $l$: clicked listing\n",
    "- $pos$: positive context listings that was clicked by *same* user before and after center listing within a **window**. Goal is to push center listing *l* closer to listings in $pos$.\n",
    "- $neg_1$ comes from randomly sampled listing.\n",
    "- Third component: use **booked listing** as global context even it falls out of the context windows. Goal is to ush center listing *l* closer to booked listing.\n",
    "- Fourth component: $neg_2$ comes from randomly sampled listing from **the same market** as center listing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Application of embeddings in personalized ranking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Base features:\n",
    "    - listing features\n",
    "    - user features\n",
    "    - query features\n",
    "    - cross-features\n",
    "    \n",
    "- Define the set of listings that a user **clicked**/**skipped** (i.e., clicked a lower ranked listing) in the last 2 weeks. ($H_c$ and $H_s$).\n",
    "- Define the similarity of item embedding and user embedding $$EmbClickSim(l, H_c) = cosine(v_l, \\sum_{l_h \\in H_c} v_{l_h})$$\n",
    "- Similar for $EmbSkipSim$. Add these ***Listing Embedding Features*** to the model to improve performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More generalized item vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- see **Document Similarity** section is [NLP Notes](../nlp_practice/Concept%20Notes.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Ranking Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top-K ranking problem instead of rating prediction problem\n",
    "- More consistent with practical user needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to evaluate a ranking system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall and Precision\n",
    "- Given user $u$, the model generates a recommendation set $R$ and true set (where the user likes/rates) $T$\n",
    "- $Recall = \\frac{R \\cap T}{T}$\n",
    "- $Precision = \\frac{R \\cap T}{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP (Average Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Average Precision = \\frac{\\sum_{k=1}^{N}{P(k) * rel(k)}}{K} $\n",
    "- $P(k)$ is precision of first k results\n",
    "- $rel(k)$ is binary value 0/1\n",
    "- $K$ is total number of relevant items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://slideplayer.com/2295316/8/images/4/Mean+Average+Precision.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain (NDCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The premise of DCG is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result.\n",
    "- Note: rel(i) here can be any value instead of binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.slidesharecdn.com/colmujsktqk4sh7faxcd-signature-f4a0831a458d6bbb78c09b1a397c3517fe8a2c82e9751f039f832a3be97b108f-poli-141208101339-conversion-gate02/95/florian-douetteau-dataiku-7-638.jpg?cb=1418033719\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Discounted_cumulative_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage\n",
    "<img src=\"https://slideplayer.com/10441443/35/images/7/Coverage+Measure+the+ability+of+recommender+system+to+recommend+all+items+to+users.+Entropy%2C+Gini+Index..jpg\" width=\"400\">\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/divers-111026095821-phpapp01/95/towards-diverse-recommendation-72-728.jpg?cb=1319623189\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other metrics:\n",
    "Diversity, AUC, F1, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pointwise\n",
    "    - Given user u and item i, predict score x\n",
    "    - Not necessary, since the score is not important; ranked list is important.\n",
    "    - Actually solving a *regression* problem\n",
    "    - The relationships between documents sometimes not considered\n",
    "    - Usually: regression, classification, etc\n",
    "    \n",
    "<img src=\"https://image.slidesharecdn.com/l2rrecysystutaly-final-131012040539-phpapp01/95/learning-to-rank-for-recommender-systems-acm-recsys-2013-tutorial-40-638.jpg?cb=1381555055\" width=\"400\">\n",
    "    \n",
    "    \n",
    "- Pairwise\n",
    "    - Goal is to correctly determine a>b or a<b for each document pair\n",
    "    - The scale of difference is ignored\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/l2rrecysystutaly-final-131012040539-phpapp01/95/learning-to-rank-for-recommender-systems-acm-recsys-2013-tutorial-46-638.jpg?cb=1381555055\" width=\"400\">\n",
    "\n",
    "- Listwise\n",
    "    - Directly optimize final performance metric\n",
    "    - More complicated modelling\n",
    "    \n",
    "<img src=\"http://baogege.info/img/learning-to-rank-for-recommender-system/listwiseltrrs.png\" width=\"400\">    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTR (Click-Through Rate) Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given (user, item, context): predict click = 0/1\n",
    "- Goal: $P(Click=1|User, Item, Context)$\n",
    "- Difference: in recommendation system and in online ad. \n",
    "- The former mainly cares about ranking, while the latter cares about accuracy, because it contributes to revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Approach - Traditional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Categorical features\n",
    "    - Millions of dimensions after one-hot encoding\n",
    "\n",
    "\n",
    "\n",
    "### Logistic Regression + Feature Engineering (Linear Model)\n",
    "- **Advantage**: simple model, good at dealing with discrete features\n",
    "- **Advantage**: linear model, can be parallelized, computational efficient\n",
    "- Main **problem**: \n",
    "    - feature combination\n",
    "    - high-order interaction\n",
    "    - only linear relationship \n",
    "    - cannot learn unseen combinations\n",
    "- For example: gender and clothes type; manual interaction is required\n",
    "- Extension: MLR\n",
    "\n",
    "\n",
    "### GBDT\n",
    "- Advantage: good at dealing with continous features\n",
    "- Capable of doing some feature combination (more than 2 orders)\n",
    "- Capable of doing some feature selection\n",
    "- Again, like LR, cannot be genealized well\n",
    "\n",
    "### Degree-2 Polynomial Mappings \n",
    "- Combine features by $y(X)=w_0 + \\sum_{i=1}^{N}{w_{1i}x_i} + \\sum_{i=1}^{N}\\sum_{j=i+1}^{N}{w_{2ij}x_ix_j} $, where N is number of features\n",
    "- Sparse data (Cannot solve if there is even no $x_i = x_j = 0$ for some $i, j$)\n",
    "- High dimension: $O(n^2)$\n",
    "- Make trivial prediction on those unseen pairs\n",
    "    \n",
    "<img src=\"http://ailab.criteo.com/wp-content/uploads/2017/03/Screen-Shot-2017-02-10-at-11.12.46-AM-789x121.png\" width=\"400\">   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorization Machine (FM)\n",
    "- Known: for matrix $W$, and a large $K$, $W \\approx \\mathbf V\\mathbf V^T$, i.e., $w_{ij} \\approx <\\mathbf v_i, \\mathbf v_j>$ \n",
    "-  $y(\\mathbf x)=w_0 + \\sum_{i=1}^{N}{w_{1i}x_i} + \\sum_{i=1}^{N}\\sum_{j=i+1}^{N}{<\\mathbf v_i, \\mathbf v_j>x_ix_j} $\n",
    "- $\\mathbf v_i, \\mathbf v_j - R^{N \\times K}$, latent vector for feature $i$ and $j$ with embedding length $K$, and totally $N$ features\n",
    "    - $\\mathbf v_i = (v_{i,1}, v_{i,2},...,v_{i,f},...)$, where $i$ is index for feature, $f$ is index for feature space\n",
    "    - $\\frac{\\partial y}{\\partial v_{i,f}} = x_i \\sum_{j=1}^N v_{j,f}x_j-v_{i,f}x_i^2$. \n",
    "    - Intuively, gradient direction is towards $v_{j,f}$ wherever $x_i$ and $x_j$ are both one.\n",
    "- Some advantages:\n",
    "    - Reasonable prediction for unseen pairs (i.e., sparse data)\n",
    "    - Lower dimension compared with polynomial: $O(N \\times K)$\n",
    "\n",
    "<img src=\"http://ailab.criteo.com/wp-content/uploads/2017/03/Screen-Shot-2017-02-10-at-11.12.53-AM-768x301.png\" width=\"400\">\n",
    "\n",
    "<img src=\"./figure/fm2.png\" width=\"600\">   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field Factorization Machine (FFM)\n",
    "- Split the original latent space into many “smaller” latent spaces,  and depending on the fields of features, one of them is used.\n",
    "- For example: weather, location, gender; intuitively, they should have different interactions\n",
    "- $y(X)=w_0 + \\sum_{i=1}^{N}{w_{1i}x_i} + \\sum_{i=1}^{N}\\sum_{j=i+1}^{N}{<\\mathbf v_{i, f_j}, \\mathbf v_{j, f_i}>x_ix_j} $\n",
    "<img src=\"http://ailab.criteo.com/wp-content/uploads/2017/03/Screen-Shot-2017-02-10-at-11.13.03-AM-768x230.png\" width=\"400\"> \n",
    "- Higher dimension: $O(N \\times K \\times F)$, where $F$ is number of fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT + LR (Mixed)\n",
    "- **Motivation**: GBDT transforms features, reduced dimensions, combined attributes\n",
    "- The leaves serve as new input features for LR\n",
    "- Drawback:\n",
    "    - Two phase modelling, i.e., LR doesn't impact GBDT\n",
    "    - Tree not very good for high-dimension sparse features because trees tend to overfitting because penalty is imposed on tree nodes/depth while LR penalizes weights\n",
    "    - For example, there is feature X with value 1 on 10 samples and value 0 on 9990 samples. In GBDT it is perfect node split because it takes only 1 depth and 1 split, while in LR it will be regularized for big weight.\n",
    "- Alternative: \n",
    "    - Use GBDT for continous variables, get $gbdt(X_{continuous})$\n",
    "    - Concatenate with $X_{discrete}$ to get final $\\mathbf X$, and feed into LR.\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/PnYuan/Practice-of-Machine-Learning/master/imgs/Kaggle_CTR/gbdt-lr/gbdt-lr_2.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Approach - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Main Advantage\n",
    "    - High-order interaction is possible by nature by hidden layers\n",
    "    - Enabled interaction of more than two (>2) features\n",
    "    - Low-order is captured by shallow part\n",
    "    - Can be extended into figures/texts\n",
    "    \n",
    "    \n",
    "- Main characteristic\n",
    "    - Shallow part of model\n",
    "    - Stack part of model\n",
    "        - Concentenate\n",
    "        - Bi-Interaction\n",
    "    - Start: Embedding layer\n",
    "    - End: FC layer\n",
    "    \n",
    "<img src=\"./figure/wd.jpg\" width=\"700\">\n",
    "\n",
    "ref: https://github.com/hhlisme/Daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralCF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In traditional CF, The **Neural CF layers** are replaced with inner product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/neural_cf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM as DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Describe Factorization Machine (FM) as deep learning network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/d-fm.png\" width = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN - Extension from FM\n",
    "- Use embedding vector from FM as initialized input for DNN\n",
    "- similar motivation with GBDT + LR\n",
    "<img src=\"./figure/fnn.png\" width = \"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNN：Product-based Neural Network\n",
    "- Instead of using simply concat/add in the DNN, **inner/outer product** is used for embedding vector interactions.\n",
    "\n",
    "\n",
    "- Two parts inside the product layer:\n",
    "    - z: original embedding vectors \n",
    "    - p: inner/outer product of embedding vectors\n",
    "- Drawback: high complexity\n",
    "    - note that from inner product layer to hidden layer 1 we have $(D_1  + M) \\cdot N \\cdot N$, where $N$ is number of features and $M$ is dimension of embedding vector, which can be simplified as $D_1 \\cdot M \\cdot N$\n",
    "    - If outer product is used, time complexity would be $D_1 \\cdot M \\cdot N \\cdot N \\cdot M$, , which can be simplified as $D_1 \\cdot M \\cdot (N+M)$\n",
    "\n",
    "\n",
    "<img src=\"./figure/pnn.png\" width = \"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFM (Attentional Factorization Machines)\n",
    "reference: https://arxiv.org/pdf/1708.04617.pdf\n",
    "<img src=\"./figure/afm.png\" width=\"800\"> \n",
    "- Motivation: similar as FFM -> Different interactions between different combinations of features\n",
    "- Weights learned automatically from a DNN\n",
    "- If we set **p** as 1, b as 0, and remove $\\alpha$, it will downgrade to FM.\n",
    "- Still, cannot learn high-order interactions.\n",
    "\n",
    "\n",
    "- $$\\hat{y}=w_0+\\sum_{i=1}^n w_i x_i+p^T\\sum_{i=1}^n \\sum_{j=i+1}^n\n",
    "\\alpha_{ij}(v_i\\odot v_j)x_ix_j$$\n",
    "- $$e_{ij} = h^T ReLU(W \\cdot  [v_i * v_j] x_i x_j  + b)$$\n",
    "- $$\\alpha_{ij} = \\frac {exp(e_{ij})}{\\sum_{i,j} exp(e_{ij})}$$\n",
    "- parameters: p, b, W, h\n",
    "- W = T(number of hidden layers) X K (number of embedding dimensions)\n",
    "- h = T X 1, b = T X 1\n",
    "- p = K X 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFM - Neural Factorization Machines\n",
    "\n",
    "-  Combine features by $y(X)=w_0 + \\sum_{i=1}^{N}{w_{1i}x_i} + f(x)$, where N is number of features\n",
    "- Define Bi-interaction layer: $f_{BI}\\mathbf (V) = \\sum_i \\sum_j x_i v_i \\odot x_j v_j$ (i.e., sum pooling with an output of $K$ dimension vector)\n",
    "\n",
    "<img src=\"./figure/element.png\" width=\"300\">\n",
    "\n",
    "\n",
    "Below is the deep part of NFM (i.e, $f(x)$ term). It needs to be concatenated with 0 and 1 order terms (i.e., $wx + b)$ as the final output $\\hat y$.\n",
    "\n",
    "Difference with ***Deep FM***:\n",
    "\n",
    "- In DeepFM: \n",
    "    - Low order interactions from FM **AND** higher order interactions from DNN\n",
    "    - Concatenation increases number of parameters, while here bi-interaction reduces complexity\n",
    "    \n",
    "    \n",
    "- In NFM: \n",
    "    - Low order interactions from FM **THEN** higher order interactions from DNN\n",
    "    - Sum of element-wise product <span style=\"color:red\">Loses</span> informaion, <span style=\"color:blue\">But</span> reduced parameters\n",
    "\n",
    "|Type|Characteristic|Example|\n",
    "|:-:|:-:|:-:|\n",
    "|Type1|FM and DNN are separately calculated, and then concatenated|DeepFM，DCN，Wide&Deep|\n",
    "|Type2|The 1st and 2nd order calculation of FM is used as input for DNN|FNN, PNN,NFM,AFM|\n",
    "\n",
    "---\n",
    "\n",
    "<img src = \"./figure/nfm.png\" width = \"700\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONN：Operation-aware Neural Network\n",
    "- a combination of FFM and NN\n",
    "    - have different embeddings for different feature interactions\n",
    "    - have DNN to capture high-order interaction\n",
    "    \n",
    "    \n",
    "- FM:<img src = \"./figure/fm3.png\" width = \"700\">\n",
    "\n",
    "- FFM:<img src = \"./figure/ffm2.png\" width = \"700\">\n",
    "\n",
    "- PNN:<img src = \"./figure/pnn2.png\" width = \"700\">\n",
    "\n",
    "- ONN:<img src = \"./figure/onn.png\" width = \"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide and Deep\n",
    "- Memorization: learning the directly relevant frequent co-occurrence of items;\n",
    "- Generalization: improving the diversity exploring new items combinations that have never or rarely occurred in the past.\n",
    "- **Wide/Shallow**: LR for categorical variables --> Memorization\n",
    "- **Deep/Stack**: DNN for continous/categorical variables --> Generalization\n",
    "<img src=\"https://1.bp.blogspot.com/-Dw1mB9am1l8/V3MgtOzp3uI/AAAAAAAABGs/mP-3nZQCjWwdk6qCa5WraSpK8A7rSPj3ACLcB/s1600/image04.png\" width=\"800\">\n",
    "---\n",
    "<img src=\"http://edarchimbaud.github.io/img/2016-11-22-wide-and-deep-learning-for-recommender-systems/Screenshot%20from%202016-11-22%2021-07-22.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An example from https://zhuanlan.zhihu.com/p/37823302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/net_1.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network structure**\n",
    "\n",
    "Part 4: Wide Part, including position bias, some categorical features to enable memorization\n",
    "\n",
    "Part 1: Deep Part, including categorical features\n",
    "- User ID / Item ID / Area ID\n",
    "- Some discretized continuous features\n",
    "- Missing / Lower frequency IDs treated as separate value\n",
    "\n",
    "Part 2: Deep Part, including continuous features\n",
    "- Some statistics\n",
    "- Text\n",
    "- Image\n",
    "\n",
    "Part 3: FC, Activation layer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep FM\n",
    "- Ref: https://www.ijcai.org/proceedings/2017/0239.pdf\n",
    "\n",
    "- Comparison with ***Wide & Deep***:\n",
    "    - FM and Deep parts shares the same inputs; In wide&deep, the two parts are independent\n",
    "    - Compared with wide&deep based on manually created features, Deep FM contains the inner product of feature latent vectors (automatically)\n",
    "    \n",
    "    \n",
    "- Network structure\n",
    "    - Directly from very sparse layer: zero and first order terms\n",
    "    - Very sparse -> Dense layer: \n",
    "        - from the neuron of $i^{th}$ feature: $\\mathbf v_i$ = $[v_{i1},...,v_{i,f}]$ for $i^{th}$ feature becomes the network weights ($V_i$ in the figure below).\n",
    "        - from a field of neurons: their embedding shares the same set of $f$\n",
    "        - One solution for multi-value field (for example: likes both apple and banana), then take average of two densed vectors (i.e., ***Average Pooling***)<img src=\"./figure/embed.png\" width=\"500\">\n",
    "         \n",
    "    - FM Layer, captures the lower (2) order combinations: Red arrow means 1 weight: $<\\mathbf v_i, \\mathbf v_j>x_ix_j $\n",
    "    - Deep/Stack layers: captures the higher order combinations, separate from FM\n",
    "    - $y_{DeepFm}=sigmoid(y_{FM}+y_{DNN})$\n",
    "\n",
    "<img src=\"./figure/deepfm.png\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ref: https://arxiv.org/pdf/1904.12579.pdf\n",
    "\n",
    "<img src = \"./figure/nffm.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIN - Deep Interest Network\n",
    "- Ref: https://arxiv.org/pdf/1706.06978.pdf\n",
    "- Main advantage:\n",
    "    - Considers **diversity** of user interest instead of embedding user history in the same way regardless of given candidate item.\n",
    "    - **Local activation** helps linking only part of user's history with the candidate item (e,g., swimming cap - goggle). \n",
    "    - In other words, a weighted average pooling for user behavior history vectors.\n",
    "    - <span style=\"color:blue\">another form of **Attention** mechanism</span>\n",
    "\n",
    "<img src=\"./figure/din_1.png\" width=\"900\">   \n",
    "    \n",
    "- Example of feature input\n",
    "<img src=\"./figure/table.png\" width=\"500\">\n",
    "<img src=\"./figure/feature_input\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison with traditional network\n",
    "    - Key formula for user embedding: \n",
    "    $$V_{user} = f(v_A, e_1, e_2, ..., e_H) = \\sum_{j=1}^H g(e_j, v_A) \\cdot e_j = \\sum_{j=1}^H w_je_j$$ where $A$ is candidiate item id, $j$ is user's historical item id.\n",
    "<img src=\"./figure/two models.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the attention weights are calculated. A simple version would be just dot product. <img src=\"./figure/two model 2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCN - Deep & Cross Network\n",
    "- ref: https://arxiv.org/abs/1708.05123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compared with ***Wide & Deep / DeepFM***: \n",
    "    - The right deep part is unchanged. \n",
    "    - The left FM part is replaced with an Cross Net. \n",
    "\n",
    "\n",
    "- The motivation is similar:\n",
    "    - To explicitly learn feature interactions (like FM part in DeepFM)\n",
    "    - To capture feature interactions of **high orders**.\n",
    "    - To apply ResNet in the interaction part so that in each step, so we can still keep original inputs.\n",
    "    - Computationally more efficient than DNN: $L (number\\ of\\ layers)\\times d(dimension\\ of\\ embedding)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/dc2.png\" width=\"300\">\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"./figure/dc1.png\" width=\"500\">\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"./figure/dc4.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Key: $x_{l+1} = x_0 x_l^Tw_l + b_l + x_l = f(x_l, w_l, b_l) + x_l$\n",
    "\n",
    "- Drawbacks\n",
    "    - Note that $x_L = \\alpha_k x_0 = g(x_0, \\mathbf w, \\mathbf b) x_0$ where $\\alpha_k$ is a scalar. This is one of the limitations of bitwise interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xDeepFM - eXtreme Deep Factorization Machine\n",
    "- ref: https://arxiv.org/pdf/1803.05170.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with Deep & Cross:\n",
    "- Same: Cross feature explicitly in **high order**\n",
    "- Improvement: **Vector-wise interaction**\n",
    "\n",
    "\n",
    "<img src=\"./figure/xf.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Compressed Interaction Network\n",
    "- $m$: number of features\n",
    "- $H_k$: number of embedding feature vectors in $k^{th}$ layer.\n",
    "- $D$: embedding size\n",
    "\n",
    "\n",
    "- Key Idea of Interaction:\n",
    "    - p1: output from $k$ layer: $H_{k-1} \\times D$.\n",
    "    - p2: input: $m \\times D$\n",
    "    - Outer product for each $d$: $Z = H_{k-1} \\times m \\times  D$\n",
    "\n",
    "\n",
    "- Key Idea of Compression:\n",
    "    - Number of channels: $m$\n",
    "    - Size of picture: $H_{k-1} \\times D$\n",
    "    - Filter Size: $H_{k-1} \\times m \\times 1$\n",
    "    - Output dimension of one filter applied on $Z$: $D \\times 1 $\n",
    "    - Number of Filters: $H_k$\n",
    "    - Output of all Filters applied on $Z$: $D \\times H_k$\n",
    "    - Output of Sum Pooling (keep one value for each filter): $1 \\times H_k$\n",
    "    - Concat the outputs of $K$ layers: length - $[H_1; H_2; ..;H_k]$\n",
    "    \n",
    "    \n",
    "- Number of Parameters:\n",
    "$$H_{k-1} \\times m \\times H_k \\times K$$\n",
    "\n",
    "\n",
    "- Drawbacks:\n",
    "    - high time complexity\n",
    "    - loss of information in sum poolings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "reference: https://zhuanlan.zhihu.com/p/69050253\n",
    "<img src=\"./figure/model_summary_3.png\" width=\"800\">\n",
    "<img src=\"./figure/model_summary_2.png\" width=\"800\">\n",
    "<img src=\"./figure/model_summary.png\" width=\"800\">\n",
    "<img src=\"./figure/model_summary3.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New models from industry/papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESMM - Entire Space Multitask Model\n",
    "- ref: https://arxiv.org/pdf/1804.07931.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- User behavior: Impression -> Click -> Buy\n",
    "- CVR, CTR, CTCVR \n",
    "<img src=\"./figure/ctcvr.png\" width=\"400\">\n",
    "<img src=\"./figure/emss2.png\" width=\"300\">\n",
    "    - where $x$ is impression, $y$ is click, $z$ is conversion.\n",
    "\n",
    "\n",
    "- Goal is to address  for CVR\n",
    "    - **Sample selection bias**: trained on clicked data but inference made on all impressions.\n",
    "    - **Data sparsity**: not so many clicks\n",
    "\n",
    "\n",
    "- Network structrure: In ESMM, two auxiliary tasks of CTR and CTCVR are\n",
    "introduced which\n",
    "    - Help to model CVR over entire input\n",
    "space\n",
    "    - Provide feature representation transfer learning.\n",
    "    - Embedding parameters of CTR and CVR network\n",
    "are shared. \n",
    "    - CTCVR takes the product of outputs from\n",
    "CTR and CVR network as the output.\n",
    "<img src=\"./figure/essm.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss Function\n",
    "    - CTR task\n",
    "    $$L_1 = - y_i\\ log\\ P_{ctr}(x_i;\\theta_{ctr}))$$\n",
    "    - CTCVR task\n",
    "    $$L_2 = - z_iy_i\\ log\\ P_{ctr}(x_i;\\theta_{ctr}))\\ P_{cvr}(x_i;\\theta_{cvr}))$$\n",
    "    - CVR task: **None**\n",
    "    $$L=L_1+L_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSTN - Deep Spatio-Temporal Neural Networks\n",
    "- ref: https://arxiv.org/pdf/1906.03776.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Definition\n",
    "- <img src=\"./figure/dstn.png\" width=\"700\">\n",
    "\n",
    "Feature Embedding\n",
    "- <img src=\"./figure/dstn1.png\" width=\"300\">\n",
    "\n",
    "- <img src=\"./figure/dstn3.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DSTN - Pooling Model**\n",
    "- (+) Pooling Layer: address the difference in number of contextual/clicked/pooling ads\n",
    "- (+) Apply weights on the embedding vectors of 4 different types of ads\n",
    "- (-) Loss of information in the Pooling layer\n",
    "- (-) The embedding layer is shared; no interaction with target ads\n",
    "\n",
    "**DSTN - Interaction Attention Model**\n",
    "$$ \\mathbf x_c = \\sum_{i=1}^{n_c} \\alpha_{c,i} (x_t, x_{c,i}) x_{c,i} $$\n",
    "where $ \\alpha_{c,i} (x_t, x_{c,i})$ is modeled through one-layer NN\n",
    "$$ \\alpha_{c,i} (x_t, x_{c,i}) 　＝ exp [ h^T ReLU( W[x_t;x_{c,i}] + b_1) + b_2]$$\n",
    "\n",
    "- (+) Interaction between target and contextual\n",
    "- (+) No normalization on attention scores (to avoid all useless ads but with scores summing up to 1)\n",
    "\n",
    "**Interpretation of attention scores**\n",
    "<img src=\"./figure/dstn4.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MA-DNN - Memory Augmented Deep Neural Network\n",
    "- ref: https://arxiv.org/pdf/1906.03776.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/ma1.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Last layer: $$ y = sigmoid(Z_L) $$\n",
    "- Motivation: \n",
    "    - $Z_L$ is the representation of target embedding.\n",
    "    - Define memory vector for a given user $u$: $m_{u0}$ and $m_{u1}$. (i.e., represents the users' preference: like and dislike).\n",
    "\n",
    "- Loss Functions:\n",
    "    - $$L_1 = -\\sum [ylogp + (1-y)log(1-p)]$$\n",
    "    - $$L_2 = \\sum [y \\cdot m_{u1} + (1-y) \\cdot m_{u0} - Z_L]^2$$\n",
    "    - Motivation: memorize the output $Z_L$ of the last FC layer as high-level abstraction of target ad.\n",
    "    - Demonstrated the merit of RNN (i.e., accounts for historical behaviors) while reduces complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIEN - Deep Interest Envole Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Approach - Reinforced Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRN - Deep Reinforcement Learning\n",
    "- ref: https://dl.acm.org/doi/10.1145/3178876.3185994\n",
    "\n",
    "<img src=\"./figure/dqn3.png\" width=\"700\">\n",
    "\n",
    "- Model:\n",
    "    - DDQN - Deep Reinforcement Learning with Double Q-learning\n",
    "\n",
    "<img src=\"./figure/dqn_e.png\" width=\"500\">\n",
    "\n",
    "---\n",
    "<img src=\"./figure/ddpg.png\" width=\"300\">\n",
    "\n",
    "- Main advantage\n",
    "    - Dynamic nature of user interest\n",
    "    - Combination of short-term and long-term reward\n",
    "- $\\color{blue}{State}$\n",
    "    - user features: statistics of news that the user clicked in the last hour/day\n",
    "    - context: time of day, etc.\n",
    "- $\\color{red}{Action}$\n",
    "    - news features: provider, topic, history clicks\n",
    "    - user-news interaction: e.g., the frequency of the type of news $i$ clicked by user $u$\n",
    "- Two components of rewards\n",
    "    - news click (short-term)\n",
    "    - user activeness (long-term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figure/www2018-3-fig2.png\" width = \"400\">\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"http://deliveryimages.acm.org/10.1145/3190000/3185994/images/www2018-3-fig4.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Deep Reinforcement Learning for List-wise Recommendations\n",
    "\n",
    "- ref: https://arxiv.org/abs/1801.00209\n",
    "\n",
    "- Network structure comparison\n",
    "    - Network a) - Cannot fit high action space (e.g., recommendation system)\n",
    "    - Network \n",
    "    b) - The network computes Q value for each action, separately, increasing time complexity\n",
    "    - Network c) - Actor-Critic algorithm (see benefits in [Reinforcement Learning Notes](../reinforcement_learning_practice/Concept%20Notes.ipynb))\n",
    "    \n",
    "- Action\n",
    "    - recommenda $K$ items instead of one\n",
    "<img src=\"./figure/DQN.png\" width=\"800\">  \n",
    "<img src=\"./figure/Actor-Critic.png\" width=\"600\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some feature engineering issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General**\n",
    "- For continuous variables\n",
    "    - standardize for NN inputs\n",
    "    - discretize for LR\n",
    "    \n",
    "    \n",
    "    \n",
    "- For discrete variables\n",
    "    - One-got encoding\n",
    "    - Text: BoW(n-gram), TF-IDF\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List/Type of features**\n",
    "- User Characteristic\n",
    "    - Demographic\n",
    "    - Behavior, preference, activeness\n",
    "- Business Characteristics\n",
    "    - Type, city, star, etc\n",
    "    - Image\n",
    "- Query\n",
    "    - Tokens, similarity\n",
    "- Context\n",
    "    - Time, distance, competition\n",
    "    - Position bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key feature: user behavior**\n",
    "- Real time user behavior\n",
    "    - Clicked Business (C_P)\n",
    "    - Ordered Business (O_P)\n",
    "    - Queries (Q)\n",
    "    - Sortings (S)\n",
    "    - Business Characteristic (C_Type, O_Type, C_Loc, O_Loc)\n",
    "    \n",
    "    \n",
    "- Problem: Sparsity of C_P, O_P, Q, S\n",
    "- Fix: separate model to describe **USER** based on user behavior \n",
    "    - Predict next time t user behavior based on LTSM\n",
    "    - Doc2Vec to get embedding of a user based on behaviors\n",
    "    - Topic modelling\n",
    "    - Serve as continous feature in Part 2\n",
    "\n",
    "\n",
    "**Some examples of extra features**\n",
    "- Statistics for different types of behaviors, for example, conversion rate, device, etc.\n",
    "    - Counting features like device ip count, device id count, hourly user count, user count\n",
    "    - Bagging features\n",
    "        - user|app id|bag of app id\n",
    "        - user1| A |A, B\n",
    "        - user1| B |A, B\n",
    "        - user2| C |C, D\n",
    "        - user2 |D |C, D\n",
    "    - Click history\n",
    "        - label| user |history\n",
    "        - 0 |user1|\n",
    "        - 1 |user1 |0\n",
    "        - 1 |user1 |01\n",
    "        - 0 |user1 |011\n",
    "- Paattern/Series of behaviors (A-B-C)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Starting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For new users:\n",
    "- Provide most popular items\n",
    "- Provide results based on demographic attributes (gender, age, etc)\n",
    "- Ask users to provide feedback on some items before providing recommendation\n",
    "\n",
    "\n",
    "For new items:\n",
    "- If using user-based CF, then as long as some user finds the items from other sources, it will be spread among users\n",
    "- If using item-based CF, then have to use item content to calculate item similarity, otherwise it will never be presented to users\n",
    "    - Calculate item-similarity by vectorizing items\n",
    "    - A strong feature would actually help content-based recommendation out-perform CF\n",
    "    \n",
    "- Some examples of similarity w/o user behavior history\n",
    "    - keyword vector of an item title with the help of NER\n",
    "    - TF-IDF of a text\n",
    "    - LDA topic modelling (use topic vector to calculate similarity)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "632px",
    "left": "0px",
    "right": "1261.17px",
    "top": "106.992px",
    "width": "220.667px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
