{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://book.douban.com/subject/30243136/\n",
    "# Part I: Modelling Approaches\n",
    "## Performance Metric\n",
    "  - F1 score: 2/F = 1/P + 1/R\n",
    "  - Other interpretations for AUC: \n",
    "    - Wilcoxon Test of Ranks\n",
    "    - Gini-index: Gini+1 = 2*AUC\n",
    "    - Not sensitive to predicted score\n",
    "\n",
    "## Feature Engineering and Feature Selection\n",
    "\n",
    "***Continuous Variables***\n",
    "  - Bucketing for continuous variables in, for example, logistic regression (by width or by percentile)\n",
    "  - Missing value treatment (imputation or code dummy variables)\n",
    "  - Feed RF nodes to linear models\n",
    "\n",
    "***Discrete Variables***\n",
    "- Cross-interaction\n",
    "- Statistics (e.g., unique values of B for each A)\n",
    "\n",
    "***Time, Space, Text Features***\n",
    "\n",
    "## Popular Models\n",
    "***Logistic Regression***:\n",
    "- Why not OLS (outliers)\n",
    "- How to solver: GD, or stochastic GD (Google FTRL)\n",
    "- Advantage: Fast, scalable\n",
    "\n",
    "***FM***\n",
    "- Motivation: \n",
    "   - Feature interaction (not done manually)\n",
    "   - Polynomial kernel (too many parameters, too sparse matrix)\n",
    "- Approach: \n",
    "  - Instead of learning all co-occurrence of i and j, the weight w is calculated as the dot product of v_i and v_j with dimension k. \n",
    "  - Here assumption is imposed on matrix W so that it can be de-composed.\n",
    "  - The parameters for different combinations are no longer independent\n",
    "- Improvement: \n",
    "  - FFM to map similar features into a *field* \n",
    "- Application:\n",
    "   - Serve as embedding for NN (e.g., User and Ad similarity)\n",
    "   - Outperforms GBDT for learn complicated feature interactions (due to sparse combinations)\n",
    "\n",
    "***GBDT***\n",
    "- Compared with Linear Models: Missing value, Range difference of attributes,, outliers, interactions, non-linear decision boundary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***GBRank***\n",
    "- A point-wise ranking method. \n",
    "- For returned pair of x and y, assume the right order is x > y, and the score function is $h$ (i.e., $h(x) > h(y)$), and the function is expressed by a series of trees.\n",
    "\n",
    "\n",
    "- Define Loss function:\n",
    "$$L_i = \\sum_{i=1}^N \\{max(0, [\\tau + h(y_i) - h(x_i)])\\}^2$$\n",
    "where $\\tau$ is defined as a threshold for better definition of loss function (i.e., difference is at least $\\tau$ to have zero loss)\n",
    "\n",
    "\n",
    "- Define Gradient for pairs with non-zero loss:\n",
    "$$r_m(x_i) = \\frac{\\partial L_i}{\\partial h_{m-1}(x_i)} = -\\tau - h_{m-1}(y_i) + h_{m-1}(x_i)$$\n",
    "$$r_m(y_i) = \\frac{\\partial L_i}{\\partial h_{m-1}(y_i)} = \\tau + h_{m-1}(y_i) - h_{m-1}(x_i)$$\n",
    "\n",
    "\n",
    "- **Note:** Instead of fitting $r_m$, directly fitting $h_m - \\rho r_m$\n",
    "- For simplicity, set $\\rho = 1$\n",
    "$$h_m(x_i) = h_{m-1}(x_i) - r_m(x_i) = \\tau + h_{m-1}(y_i)$$\n",
    "$$h_m(y_i) = h_{m-1}(y_i) - r_m(y_i) = -\\tau + h_{m-1}(x_i)$$\n",
    "\n",
    "\n",
    "- Fit a regression tree $\\Delta_m $with sample points ${(x_i, h_m(x_i)),((y_i, h_m(y_i))}$\n",
    "- Get the score function $h$ for next iteration:\n",
    "$$h_m = \\frac{mh_{m-1} + \\eta \\Delta_m}{m+1}$$\n",
    "\n",
    "\n",
    "\n",
    "***RankNet***\n",
    "- A point-wise ranking method\n",
    "- For returned pair of x and y, assume the right order is x > y (i.e., $P_0 = 1$), and the score function is $f$ (i.e., $f(x) > f(y)$), and the function is expressed by a neural network.\n",
    "\n",
    "\n",
    "- Define forward network (take two layer for example, with sizes 10, 5, 1)\n",
    "$$\\underset{5 \\times 1}{f_1} = \\underset{5 \\times 10}{\\mathbf W_1} \\cdot \\underset{10 \\times 1}{\\mathbf x}$$\n",
    "$$\\underset{1 \\times 1}{f(x)} = \\underset{1 \\times 5}{\\mathbf W_2} \\cdot \\underset{5 \\times 1}{f_1} =\\underset{1 \\times 5}{\\mathbf W_2} \\cdot  \\underset{5 \\times 10}{\\mathbf W_1} \\cdot \\underset{10 \\times 1}{\\mathbf x}$$\n",
    "$$f_{xy} = f(x) - f(y)$$\n",
    "\n",
    "- Define predicted probability\n",
    "$$P_{xy} = P(f(x) > f(y)) = Sigmoid (f_{xy})$$\n",
    "\n",
    "\n",
    "- Loss is defined as cross entropy\n",
    "$$L = -P^0log(P)-(1-P^0)log(1-P)$$\n",
    "\n",
    "- Define Gradients for weights\n",
    "$$\\frac{\\partial f_x}{\\partial {\\mathbf W_2}} = \\underset{1 \\times 5}{?} = f_1^T$$\n",
    "$$\\frac{\\partial f_x}{\\partial {\\mathbf W_1}} = \\underset{5 \\times 10}{?} = \\underset{5 \\times 1}{?} \\cdot \\underset{1 \\times 10}{?} =  {\\mathbf W_2^T} \\cdot  {\\mathbf x^T}$$\n",
    "\n",
    "- Define Gradient for output $f$\n",
    "$$\\frac{\\partial L}{\\partial f_{xy}} = P_{xy} - P_0 = Sigmoid (f_{xy}) - P^0 $$\n",
    "\n",
    "- Define update rule\n",
    "$$\\frac{\\partial L}{\\partial {\\mathbf W}} = \\frac{\\partial L}{f_{xy}} \\cdot \\frac{\\partial f_{xy}}{f_{x}}  \\cdot  \\frac{\\partial f_{x}}{\\mathbf W}  + \\frac{\\partial L}{f_{xy}} \\cdot \\frac{\\partial f_{xy}}{f_{y}}  \\cdot  \\frac{\\partial f_{y}}{\\mathbf W} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Notes\n",
    "# 用户画像\n",
    "## 标签体系\n",
    "- LBS 例如常住城市、居住商圈\n",
    "- 人口属性， 例如性别、年龄、婚姻\n",
    "- 业务标签，例如外卖、丽人\n",
    "- 兴趣偏好，例如品类、品牌\n",
    "- 特征人群，例如亲子、有车\n",
    "- 用户分级，例如会员、用户价值\n",
    "- 用户行为，例如浏览、交易\n",
    "\n",
    "## 处理流程\n",
    "- 用户标识与特征工程\n",
    "- 标签产生平台\n",
    "    - 特征库与样本库\n",
    "    - 特征定制\n",
    "    - 模型构建\n",
    "    - 模型发布\n",
    "- 建模方法\n",
    "    - 基于规则（基于历史行为的用户品类偏好）\n",
    "    - 样本明确（例如预测年龄等）\n",
    "    - 小样本（精准营销）\n",
    "- 应用场景\n",
    "    - 根据用户的ID查询用户画像，根据画像数据进行个性化推荐\n",
    "    - 根据画像数据作为查询条件\n",
    "    \n",
    "# POI 实体链接\n",
    "两种思路：\n",
    "- 聚类分析，同一个cluster则是同一个实体（实时性差，不能实施计算新实体）\n",
    "- 建立索引缩小候选集（索引粒度，召回率，候选集大小的tradeoff）\n",
    "\n",
    "一个例子：酒店实体\n",
    "- 选择关键字段：名称、地址、电话、经纬度\n",
    "- 训练线下模型\n",
    "- 通过索引找出potential链接，应用模型解决二分类问题\n",
    "\n",
    "# 评论挖掘\n",
    "- 中文NLP预处理\n",
    "    - 噪声、错别字的删除与替换\n",
    "    - 中文分词\n",
    "        - 词义消歧（例如用wordvec替换为语义层面相近的词）\n",
    "        - 预定义词表（专有名词）\n",
    "        - 未登录词\n",
    "        - PoS\n",
    "        - NER\n",
    "    - 长句切分\n",
    "    - 去除停用词\n",
    "    - 词向量\n",
    "- 无监督与有监督问题\n",
    "- 情感分析\n",
    "    - 评论情感分析的特殊性\n",
    "        - 长短不一，实时性事件\n",
    "        - 情感负责，正负存在于同一样本\n",
    "        - 正负样本比例\n",
    "        \n",
    "# 查询理解\n",
    "- 倒排索引的概念（建立索引表，根据搜索条件求交集）\n",
    "- 意图识别 \n",
    "    - 餐饮，酒店，景点等\n",
    "    - 建立多个二分类模型。例子:黄鹤楼，酒店或景点\n",
    "- 实体识别\n",
    "- 召回策略\n",
    "    - 特定查询只在特定文本域求交\n",
    "    - 将不同成分映射到不同文本域做检索（即利用实体识别的产出，例如望京的涮羊肉->商圈索引域+品类索引域）\n",
    "- 查询改写\n",
    "    - 同义词：宾馆，客栈\n",
    "    - 下位词：陕西美食，羊肉泡馍\n",
    "    - 方法：Session挖掘，二部图，语义向量\n",
    "- 词权重\n",
    "    - TF-IDF\n",
    "    - 基于规则\n",
    "    - 基于统计学习\n",
    "\n",
    "# 用户引导\n",
    "- 搜索前引导：例如历史搜索词，推荐系统\n",
    "- 搜索中引导：查询补全\n",
    "- 搜索后引导：相关查询、商家推荐\n",
    "\n",
    "# 排序\n",
    "- 主要特点：移动化、场景化、本地化、个性化\n",
    "- 排序模型：Point-wise与Pair-wise\n",
    "- 场景化：不同场景对应不同模型\n",
    "- 评价指标：Prec@K, AP, MAP（AUC不适用，不直接反映排序的好坏）\n",
    "\n",
    "# 推荐\n",
    "- 主要特点：地理位置附近、用户历史行为、实施即时推荐\n",
    "- 推荐召回\n",
    "    - 协同过滤\n",
    "    - 实时位置\n",
    "    - 实时行为\n",
    "    - 替补策略\n",
    "- 推荐排序\n",
    "    - 主要特征：用户、Item、场景\n",
    "    - 样本选取：\n",
    "        - 如何选正样本？Skip-Above\n",
    "        - 负样本补充？曝光数据\n",
    "        - 样本权重：支付、下单、点击\n",
    "- 推荐系统评价指标\n",
    "\n",
    "# 计算广告\n",
    "- 特点：三方利益（平台、商户、用户）\n",
    "- 不同评价标准：\n",
    "    - 商户：可见性、线上增量收益、整体增量收益、ROI\n",
    "    - 用户：CTR与CVR\n",
    "    - 平台：Revenue = # of Impression * CTR * CPC\n",
    "- 不同的召回机制\n",
    "    - 搜索场景广告\n",
    "        - 根据用查询词在广告索引中寻找匹配的商户\n",
    "        - 相比自然排序，业务目标不同：除排序正确还需要考虑CTR准确\n",
    "    - 推荐场景广告\n",
    "        - 推送广告：根据时间、用户历史、地理位置、（已知和估计的）人口属性、用户偏好、Look-Alike等来定向(p188)\n",
    "        - 主要考量：点击、转化率与覆盖率的平衡，不能太窄或太泛\n",
    "- 排序\n",
    "    - $Rank Score = bid \\times CTR$\n",
    "    - $CTR = P(Click|AD, User, Query)$\n",
    "    - 常见的CTR模型：LR, FM, FFM, DL\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
